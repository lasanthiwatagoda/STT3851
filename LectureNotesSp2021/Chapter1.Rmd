---
title: Introduction to Statistical Learning
author: Dr. Lasanthi Watagoda
date: January 14, 2025
output:
  prettydoc::html_pretty:
    toc: true
    theme: cayman
    highlight: github
    math: katex
    number_sections: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ISLR)
```

# What is Statistical learning?

Statistical learning refers to a ________________.

These tools can be classified as:

1. 

2. 


## Supervised Learning

This involves building a statistical model for ________________, or ________________, an output based on ________________. Problems of this nature occur in fields as diverse as business, medicine, astrophysics, and public policy. 

Examples:

1) Spam detection: Spam detection is another example of a supervised learning model. Using supervised classification algorithms, organizations can train databases to recognize patterns or anomalies in new data to organize spam and non-spam-related correspondences effectively.

2) Predicting house/property price

## Unsupervised Learning

Here, there are ________________ but no supervising ________________; nevertheless we can learn relationships and structure from such data. 

Examples:

1) Data exploration
2) customer segmentation: suppose we’re working for a company that sells clothes and we have data from previous customers: how much they spent, their ages and the day that they bought the product. Our task is to find a pattern or relationship between the variables in order to provide the company with useful information so they can create marketing strategies, decide on which type of client they should focus on to maximize the profits or which customer segment they can put more effort to expand in the market.



## Data sets

To provide an illustration of some applications of
statistical learning, we briefly discuss three real-world data sets.

  1) Wage data --- `Wage`
  2) Stock Market data --- `Smarket`
  3) Gene Expression data --- `NCI60`

### Wage data --- `Wage`

In this application we examine a number of factors that relate to wages for a group of males from the Atlantic region of the United States. In particular, _we wish to understand the association between an employee’s `age` and `education`, as well as the calendar `year`, on his `wage`_. 





  
```{r warning=FALSE, message=FALSE}
library(ISLR)
data(Wage)
head(Wage)
?Wage
#dim(Wage) this will help to find ncol and n rows in the dataset
str(Wage)
```
  
  
Consider, for example, wage versus age for each of the individuals
in the data set. 

  i) Create a scatter plot (shown here) for wage versus age
  

  
```{r echo=FALSE, warning=FALSE, message=FALSE}
data(Wage)
#head(Wage)

ggplot(data = Wage, aes(x=age, y=wage)) + geom_point(color= "steelblue") + geom_smooth(se=FALSE) + theme_bw()

```
  
  
  ii) Describe the plot you created in i) 
  
$$\\[0.5in]$$
  
  
  iii) Create a scatter plot (shown here) for wage versus year
  
  
  
  
  
  
```{r echo=FALSE, warning=FALSE, message=FALSE}
ggplot(data = Wage, aes(x=year, y=wage)) + geom_point(color= "orchid4") + geom_smooth(method = lm, se = FALSE) + theme_bw()
```
  
  
  iv) Describe the plot you created in iii) 
  
$$\\[0.5in]$$
  
  v) Create a boxplot (shown here) for wage for each education level.
  
```{r echo=FALSE, warning=FALSE, message=FALSE}
ggplot(data = Wage, aes(x=education, y=wage, fill = factor(education))) + geom_boxplot() + theme_bw() +                                 
labs(title = "Boxplots displaying wage as a funtion of education",x = "Education level",y = "Wage")
```
  
  
  vi) Describe the plot you created in v) 
$$\\[0.5in]$$
  

Clearly, the most accurate prediction of a given man’s `wage` will be
obtained by combining his `age`, his `education`, and the `year`.

**Note:**
```{rnote}
The Wage data involves predicting a ________________ output value. 

This is often referred to as a ________________ problem.

```


### Stock Market data --- `Smarket`

In this case we instead wish to predict a non-numerical value—that is, a ________________ output.

```{r}
library(ISLR)
data("Smarket")
head(Smarket)
?Smarket
```

The goal is to predict whether the index will increase or decrease on a given day using the past 5 days’ percentage changes in the index. 

Here the statistical learning problem does not involve predicting a numerical value. Instead it involves predicting whether a given day’s stock market performance will fall into the ___ bucket or the ____ bucket.

**Note:**
```{rnote}
This is known as a _____________ problem.
```

  i) Create a boxplot (shown here) for yesterday's percentage change with the `Direction` variable
  
```{r echo=FALSE, warning=FALSE, message=FALSE}

p1 <- ggplot(data = Smarket, aes(y=Lag1, fill=Direction)) + geom_boxplot() +  theme_bw()
p2 <- ggplot(data = Smarket, aes(y=Lag2, fill=Direction)) + geom_boxplot() +  theme_bw()
p3 <- ggplot(data = Smarket, aes(y=Lag3, fill=Direction)) + geom_boxplot() +  theme_bw()

library(cowplot)
plot_grid(p1, p2, p3)
```
  
  
  ii) Is there any indication that there is an association between the past and present performance of the stock market?
$$\\[0.5in]$$

### Gene Expression data --- `NCI60`

The previous two applications illustrate data sets with both input and
output variables. However, another important class of problems involves
situations in which we only observe ___________ variables, with no corresponding
______________.

Example: In a marketing setting, we might have demographic
information for a number of current customers. We may wish to
understand which types of customers are similar to each other by grouping
individuals according to their observed characteristics. 

**Note:**
```{rnote}
This is known as a _____________ problem.
```


We consider the `NCI60` data set, which consists of 6830 gene expression measurements
for each of 64 cancer cell lines. Instead of predicting a particular output
variable, we are interested in determining whether there are groups, or
clusters, among the cell lines based on their gene expression measurements.
This is a difficult question to address, in part because there are thousands
of gene expression measurements per cell line, making it hard to visualize
the data.


# Summary of what we learned in this chapter:


![](MachineLearning.png)




# What do we cover in this class?

  * In Chapter 2 we introduce the basic terminology and concepts behind statistical
learning. This chapter also presents the $K$-nearest neighbor classifier, a
very simple method that works surprisingly well on many problems. 

  * Chapter 3 reviews linear regression, the fundamental starting
point for all regression methods. 

  * A central problem in all statistical learning situations involves choosing
the best method for a given application. Hence, in Chapter 5 we introduce
cross-validation and the bootstrap, which can be used to estimate the
accuracy of a number of different methods in order to choose the best one.

  * Chapter 6 we consider a host of linear methods, both
classical and more modern, which offer potential improvements over standard
linear regression. These include stepwise selection, ridge regression,
principal components regression, partial least squares, and the lasso.

